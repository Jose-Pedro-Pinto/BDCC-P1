{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BDCC_project_Loader_Cloud_Function.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm9K0GA_mj4q",
        "colab_type": "text"
      },
      "source": [
        "# BDCC project - Loader Cloud Function development\n",
        "\n",
        "**[Big Data and Cloud Computing](https://www.dcc.fc.up.pt/~edrdo/aulas/bdcc), Project 1**\n",
        "\n",
        "Make sure you go through the __[Google Cloud Functions Pub/Sub tutorial](https://cloud.google.com/functions/docs/tutorials/pubsub)__ before you start developing the LCF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYpLKlN_WVQK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## GCP authentication function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExEXfk63_79q",
        "colab_type": "code",
        "outputId": "459c304c-4f01-4bea-ce4c-3aaba29fa323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JBUnFD7WYhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The authentication method \n",
        "def google_colab_authenticate(projectId, keyFile=None, debug=True):  \n",
        "    import os\n",
        "    from google.colab import auth\n",
        "    if keyFile == None:\n",
        "      keyFile='/content/bdcc-colab.json'\n",
        "    if os.access(keyFile,os.R_OK):\n",
        "      if debug:\n",
        "        print('Using key file \"%s\"' % keyFile)\n",
        "      os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '%s' % keyFile\n",
        "      os.environ['GCP_PROJECT'] = projectId \n",
        "      os.environ['GCP_ACCOUNT'] = 'bdcc-colab@' + projectId + '.iam.gserviceaccount.com'\n",
        "      !gcloud auth activate-service-account \"$GCP_ACCOUNT\" --key-file=\"$GOOGLE_APPLICATION_CREDENTIALS\" --project=\"$GCP_PROJECT\"\n",
        "    else:\n",
        "      if debug:\n",
        "        print('No key file given. You may be redirected to the verification code procedure.')\n",
        "      auth.authenticate_user()\n",
        "      !gcloud config set project $projectId\n",
        "    !gcloud info | grep -e Account -e Project\n",
        "\n",
        "# Copy key file from Google Drive if available \n",
        "# to a path without spaces (it usually creates problems)\n",
        "!test -f \"/content/drive/My Drive/bdcc-colab.json\" && cp \"/content/drive/My Drive/bdcc-colab.json\" /content/bdcc-colab.json\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWuVMPq-VJug",
        "colab_type": "text"
      },
      "source": [
        "## Cloud function code\n",
        "\n",
        "This should be placed in a single cell to facilitate cloud function.\n",
        "\n",
        "Note that you cannot use \"magic\" notebook extensions such as `! shell command` or `%%bigquery`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6QYyjiwTciH",
        "colab_type": "code",
        "outputId": "5e0c4640-0281-4541-fac9-3813384c7d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Imports\n",
        "import base64\n",
        "import pandas as pd\n",
        "import os\n",
        "import tempfile\n",
        "import time\n",
        "from zipfile import ZipFile\n",
        "import google.cloud.bigquery as bq\n",
        "import google.cloud.storage as gcs\n",
        "\n",
        "\n",
        "# Parameters\n",
        "PROJECT_ID = 'bigdata-269209'  # TODO change to your project id\n",
        "BUCKET_NAME = 'zaoutputbucket' # TODO change to your bucket name\n",
        "PUBSUB_TOPIC = 'new_output' \n",
        "OUTPUT_ZIP_FILE = 'output.zip'\n",
        "\n",
        "DEBUG = True \n",
        "RUNNING_IN_COLAB = os.environ.get('COLAB_GPU') != None\n",
        "\n",
        "TMP_DIR=tempfile.mkdtemp(prefix='LCF_')\n",
        "\n",
        "# Debug method\n",
        "def debug(message):\n",
        "  if DEBUG:\n",
        "     print(message)\n",
        "\n",
        "# Authenticate to GCP if running in Colab\n",
        "if RUNNING_IN_COLAB:\n",
        "  google_colab_authenticate(PROJECT_ID)\n",
        "\n",
        "# Initialize interface to BigQuery and GCS\n",
        "BQ_CLIENT = bq.Client(PROJECT_ID)\n",
        "GCS_CLIENT = gcs.Client(PROJECT_ID)\n",
        "BUCKET = gcs.Bucket(GCS_CLIENT, BUCKET_NAME)\n",
        "\n",
        "def get_data_from_cloud_storage(dataset_id):\n",
        "  bucket_path = '%s/%s' % (dataset_id, OUTPUT_ZIP_FILE)\n",
        "  local_zip_file = '%s/%s' % (TMP_DIR, OUTPUT_ZIP_FILE)\n",
        "  debug('Downloading gs://%s/%s to %s' % (BUCKET_NAME,bucket_path,local_zip_file))\n",
        "  blob = gcs.Blob(bucket_path, BUCKET)\n",
        "  with open(local_zip_file, 'wb') as out:\n",
        "    blob.download_to_file(out)\n",
        "  \n",
        "\n",
        "def unzip_data_file():\n",
        "  local_zip_file = '%s/%s' % (TMP_DIR, OUTPUT_ZIP_FILE)\n",
        "  debug('Unzipping %s' % local_zip_file)\n",
        "  with ZipFile(local_zip_file) as zf:\n",
        "    zf.extractall(TMP_DIR)\n",
        "  debug('Unzipping done')\n",
        "\n",
        "def load_movie_agg_data(dataset_id):\n",
        "  tid = 'movies_agg'\n",
        "  table_name = '%s.%s.%s' % (PROJECT_ID, dataset_id, tid)\n",
        "  \n",
        "  # Read parquet file\n",
        "  parquet_files_path = '%s/%s.parquet' % (TMP_DIR, tid)\n",
        "  debug('Reading Parquet files from %s' % parquet_files_path)\n",
        "  pdf = pd.read_parquet(parquet_files_path)\n",
        "  debug(str(pdf.head(5)))\n",
        "\n",
        "\n",
        "  # Create BigQuery table\n",
        "  table = bq.Table(table_name)\n",
        "  \n",
        "  table.schema = (\n",
        "        bq.SchemaField(\"movieId\", \"INTEGER\", \"REQUIRED\"),\n",
        "        bq.SchemaField(\"title\",  \"STRING\", \"REQUIRED\"),\n",
        "        bq.SchemaField(\"year\", \"INTEGER\", \"REQUIRED\"),\n",
        "        bq.SchemaField(\"imdbId\", \"INTEGER\", \"REQUIRED\"),\n",
        "        bq.SchemaField(\"numRatings\", \"INTEGER\", \"REQUIRED\"),\n",
        "        bq.SchemaField(\"avgRating\", \"FLOAT\", \"REQUIRED\"),\n",
        "  )\n",
        "  debug('Creating %s' % table_name)\n",
        "  BQ_CLIENT.create_table(table)\n",
        "\n",
        "  debug('Populating %s with %d rows' % (table_name, len(pdf)))\n",
        "  load_job = BQ_CLIENT.load_table_from_dataframe(pdf, table)\n",
        "\n",
        "  while load_job.running():\n",
        "     debug('waiting for load job to complete')\n",
        "     time.sleep(1)\n",
        "\n",
        "  debug('Done with table %s' % table_name)\n",
        "\n",
        "def load_tfidf_data(dataset_id):\n",
        "  tid = 'tfidf'\n",
        "  table_name = '%s.%s.%s' % (PROJECT_ID, dataset_id, tid)\n",
        "  \n",
        "  # Read parquet file\n",
        "  parquet_files_path = '%s/%s.parquet' % (TMP_DIR, tid)\n",
        "  debug('Reading Parquet files from %s' % parquet_files_path)\n",
        "  pdf = pd.read_parquet(parquet_files_path)\n",
        "  pdf.movieId = pdf.movieId.astype(\"int32\")\n",
        "  debug(str(pdf.head(5)))\n",
        "\n",
        "\n",
        "  # Create BigQuery table\n",
        "  table = bq.Table(table_name)\n",
        "  \n",
        "  table.schema = (\n",
        "        bq.SchemaField(\"movieId\", \"INTEGER\", \"REQUIRED\"),\n",
        "        bq.SchemaField(\"word\",  \"STRING\", \"REQUIRED\"),\n",
        "        bq.SchemaField(\"tf_idf\", \"FLOAT\", \"REQUIRED\"),\n",
        "  )\n",
        "  debug('Creating %s' % table_name)\n",
        "  BQ_CLIENT.create_table(table)\n",
        "\n",
        "  debug('Populating %s with %d rows' % (table_name, len(pdf)))\n",
        "  load_job = BQ_CLIENT.load_table_from_dataframe(pdf, table)\n",
        "\n",
        "  while load_job.running():\n",
        "     debug('waiting for load job to complete')\n",
        "     time.sleep(1)\n",
        "\n",
        "  debug('Done with table %s' % table_name)\n",
        "\n",
        "def load_ratings_tags_data(dataset_id):\n",
        "  tid = 'ratings_tags'\n",
        "  table_name = '%s.%s.%s' % (PROJECT_ID, dataset_id, tid)\n",
        "  \n",
        "  # Read parquet file\n",
        "  parquet_files_path = '%s/%s.parquet' % (TMP_DIR, tid)\n",
        "  debug('Reading Parquet files from %s' % parquet_files_path)\n",
        "  pdf = pd.read_parquet(parquet_files_path)\n",
        "  debug(str(pdf.head(5)))\n",
        "\n",
        "\n",
        "  # Create BigQuery table\n",
        "  table = bq.Table(table_name)\n",
        "  \n",
        "  table.schema = (\n",
        "        bq.SchemaField(\"movieId\", \"INTEGER\", \"REQUIRED\"),\n",
        "        bq.SchemaField(\"title\", \"STRING\", \"REQUIRED\"),\n",
        "        bq.SchemaField(\"userId\",  \"INTEGER\", \"REQUIRED\")\n",
        "  )\n",
        "  debug('Creating %s' % table_name)\n",
        "  BQ_CLIENT.create_table(table)\n",
        "\n",
        "  debug('Populating %s with %d rows' % (table_name, len(pdf)))\n",
        "  load_job = BQ_CLIENT.load_table_from_dataframe(pdf, table)\n",
        "\n",
        "  while load_job.running():\n",
        "     debug('waiting for load job to complete')\n",
        "     time.sleep(1)\n",
        "\n",
        "  debug('Done with table %s' % table_name)\n",
        "\n",
        "def handle_pubsub_message(event, context):\n",
        "  debug('Event: %s' % event)\n",
        "  debug('Context: %s' % context)\n",
        "\n",
        "  if RUNNING_IN_COLAB:\n",
        "    dataset_id = event['data']\n",
        "  else:\n",
        "    dataset_id =  base64.b64decode(event['data']).decode('utf-8')\n",
        "  \n",
        "  debug('Dataset: %s' % dataset_id)\n",
        "  \n",
        "  get_data_from_cloud_storage(dataset_id)\n",
        "  unzip_data_file()\n",
        "  \n",
        "  debug('Deleting previous BiqQuery dataset (if any)')\n",
        "\n",
        "  BQ_CLIENT.delete_dataset(dataset_id, delete_contents = True, not_found_ok = True)\n",
        "  BQ_CLIENT.create_dataset(dataset_id)\n",
        "\n",
        "  debug('Created BiqQuery dataset')\n",
        "\n",
        "  load_movie_agg_data(dataset_id)\n",
        "  load_tfidf_data(dataset_id)\n",
        "  load_ratings_tags_data(dataset_id)\n",
        "  debug('Done for data set %s' % dataset_id)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No key file given. You may be redirected to the verification code procedure.\n",
            "Updated property [core/project].\n",
            "Account: [jprfpa@gmail.com]\n",
            "Project: [bigdata-269209]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpjEKVSRDYDi",
        "colab_type": "text"
      },
      "source": [
        "## Test cloud function locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXu1kZtl4KAI",
        "colab_type": "code",
        "outputId": "d4e61dc7-e73e-41f1-f03c-87b6a329dfc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dataset = 'large5' #@param [\"tiny1\", \"tiny2\", \"tiny3\", \"tiny4\", \"medium1\", \"medium2\", \"medium3\", \"medium4\", \"large1\", \"large2\", \"large3\", \"large4\", \"large5\"] {allow-input: true}\n",
        "handle_pubsub_message({ 'data': dataset}, None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Event: {'data': 'large5'}\n",
            "Context: None\n",
            "Dataset: large5\n",
            "Downloading gs://zaoutputbucket/large5/output.zip to /tmp/LCF_cj_ff41j/output.zip\n",
            "Unzipping /tmp/LCF_cj_ff41j/output.zip\n",
            "Unzipping done\n",
            "Deleting previous BiqQuery dataset (if any)\n",
            "Created BiqQuery dataset\n",
            "Reading Parquet files from /tmp/LCF_cj_ff41j/movies_agg.parquet\n",
            "   movieId                        title    year  imdbId  numRatings  avgRating\n",
            "0        1                    Toy Story  1995.0  114709       57309   3.893708\n",
            "1        2                      Jumanji  1995.0  113497       24228   3.251527\n",
            "2        3             Grumpier Old Men  1995.0  113228       11804   3.142028\n",
            "3        4            Waiting to Exhale  1995.0  114885        2523   2.853547\n",
            "4        5  Father of the Bride Part II  1995.0  113041       11714   3.058434\n",
            "Creating bigdata-269209.large5.movies_agg\n",
            "Populating bigdata-269209.large5.movies_agg with 62345 rows\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "Done with table bigdata-269209.large5.movies_agg\n",
            "Reading Parquet files from /tmp/LCF_cj_ff41j/tfidf.parquet\n",
            "   movieId word    tf_idf\n",
            "0    26413   07  2.476856\n",
            "1    26560   07  1.415346\n",
            "2     4856   07  0.762109\n",
            "3    73587   07  2.476856\n",
            "4    50742   07  1.651237\n",
            "Creating bigdata-269209.large5.tfidf\n",
            "Populating bigdata-269209.large5.tfidf with 1708627 rows\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "Done with table bigdata-269209.large5.tfidf\n",
            "Reading Parquet files from /tmp/LCF_cj_ff41j/ratings_tags.parquet\n",
            "   movieId      title  userId\n",
            "0        1  Toy Story       2\n",
            "1        1  Toy Story       3\n",
            "2        1  Toy Story       4\n",
            "3        1  Toy Story       5\n",
            "4        1  Toy Story       8\n",
            "Creating bigdata-269209.large5.ratings_tags\n",
            "Populating bigdata-269209.large5.ratings_tags with 25078468 rows\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "waiting for load job to complete\n",
            "Done with table bigdata-269209.large5.ratings_tags\n",
            "Done for data set large5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PvPzWdDDgKk",
        "colab_type": "text"
      },
      "source": [
        "## Trigger cloud function once it is deployed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Leax69xNGXwv",
        "colab_type": "text"
      },
      "source": [
        "Before deployment do not forget to add the following dependencies to __REQUIREMENTS.txt__ in the function definitions (note that __pyarrow__ is required for Parquet data handling using Pandas):\n",
        "\n",
        "```\n",
        "pyarrow \n",
        "pandas\n",
        "google.cloud.bigquery\n",
        "google.cloud.storage\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJecx9R7E2yH",
        "colab_type": "code",
        "outputId": "e7892ec2-9df2-4e89-a86e-c8e134fe7b7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dataset = 'large5' #@param [\"tiny1\", \"tiny2\", \"tiny3\", \"tiny4\", \"medium1\", \"medium2\", \"medium3\", \"medium4\", \"large1\", \"large2\", \"large3\", \"large4\", \"large5\"] {allow-input: true}\n",
        "!gcloud pubsub topics publish \"$PUBSUB_TOPIC\" --message \"$dataset\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "messageIds:\n",
            "- '1101138481946456'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaNyrvXAWm2T",
        "colab_type": "code",
        "outputId": "74ea99f4-f23e-443d-872e-612dbda3a799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# TODO You may now check, as in previous notebooks:\n",
        "# - your BigQuery data is ok with some queries in the notebook and/or in the BigQuery Web UI\n",
        "# - inspect function logs\n",
        "\n",
        "from google.cloud import bigquery\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "#check if tfidf was loaded properly \n",
        "tfidf_test = client.query(\n",
        "  '''\n",
        "  SELECT *\n",
        "  FROM  `%s.tfidf` \n",
        "  ORDER BY tf_idf DESC\n",
        "  LIMIT 10\n",
        "  ''' % (dataset)\n",
        ")\n",
        "\n",
        "print(tfidf_test.to_dataframe())\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#check if movies_agg was loaded properly\n",
        "movies_agg_test = tfidf_test = client.query(\n",
        "  '''\n",
        "  SELECT *\n",
        "  FROM  `%s.movies_agg` \n",
        "  LIMIT 10\n",
        "  ''' % (dataset)\n",
        ")\n",
        "\n",
        "ratings_tags_test = client.query(\n",
        "  '''\n",
        "  SELECT *\n",
        "  FROM  `%s.ratings_tags` \n",
        "  LIMIT 10\n",
        "  ''' % (dataset)\n",
        ")\n",
        "\n",
        "print(ratings_tags_test.to_dataframe())\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "cloudFunctionName = \"LCF\"\n",
        "!gcloud functions logs read $cloudFunctionName --limit 1000 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   movieId      word    tf_idf\n",
            "0    65894    blutch  15.92979\n",
            "1   133437     bicek  15.92979\n",
            "2     1764   brouwer  15.92979\n",
            "3   192981  bromhead  15.92979\n",
            "4   193629   belugou  15.92979\n",
            "5   169388  cammaert  15.92979\n",
            "6   161054     bärin  15.92979\n",
            "7    52551   bjorlin  15.92979\n",
            "8    92514  beradino  15.92979\n",
            "9   157316   arnetia  15.92979\n",
            "\n",
            "\n",
            "\n",
            "   movieId      title  userId\n",
            "0        1  Toy Story       2\n",
            "1        1  Toy Story       3\n",
            "2        1  Toy Story       4\n",
            "3        1  Toy Story       5\n",
            "4        1  Toy Story       8\n",
            "5        1  Toy Story      10\n",
            "6        1  Toy Story      12\n",
            "7        1  Toy Story      13\n",
            "8        1  Toy Story      18\n",
            "9        1  Toy Story      26\n",
            "\n",
            "\n",
            "\n",
            "LEVEL  NAME  EXECUTION_ID      TIME_UTC                 LOG\n",
            "D      LCF   1081643503488292  2020-04-02 14:15:59.264  Function execution started\n",
            "I      LCF   1081643503488292  2020-04-02 14:15:59.276  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1081643503488292  2020-04-02 14:15:59.276  Context: {event_id: 1081643503488292, timestamp: 2020-04-02T14:15:58.610Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1081643503488292  2020-04-02 14:15:59.276  Dataset: tiny1\n",
            "I      LCF   1081643503488292  2020-04-02 14:15:59.276  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_67hjicay/output.zip\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:00.361  Unzipping /tmp/LCF_67hjicay/output.zip\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:00.564  Unzipping done\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:00.564  Deleting previous BiqQuery dataset (if any)\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:01.164  Created BiqQuery dataset\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:01.164  Reading Parquet files from /tmp/LCF_67hjicay/movies_agg.parquet\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:01.481     movieId                        title  year  imdbId  numRatings  avgRating\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:01.481  0        1                    Toy Story  1995  114709         215   3.920930\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:01.481  1        2                      Jumanji  1995  113497         110   3.431818\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:01.481  2        3             Grumpier Old Men  1995  113228          52   3.259615\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:01.481  3        4            Waiting to Exhale  1995  114885           7   2.357143\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:01.481  4        5  Father of the Bride Part II  1995  113041          49   3.071429\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:01.481  Creating bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:01.863  Populating bigdata-269209.tiny1.movies_agg with 10 rows\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:03.629  waiting for load job to complete\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:04.740  waiting for load job to complete\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:05.807  waiting for load job to complete\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:07.057  waiting for load job to complete\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:08.159  waiting for load job to complete\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:09.338  Done with table bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:09.338  Reading Parquet files from /tmp/LCF_67hjicay/tfidf.parquet\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:10.610     movieId      word    tf_idf\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:10.610  0        3       ann  1.660964\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:10.610  1        1       tom  1.160964\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:10.610  2       10  scorupco  3.321928\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:10.610  3        1  children  0.868483\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:10.610  4        9    boothe  3.321928\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:10.610  Creating bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:10.776  Populating bigdata-269209.tiny1.tfidf with 142 rows\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:12.224  waiting for load job to complete\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:13.288  waiting for load job to complete\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:14.359  waiting for load job to complete\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:15.535  waiting for load job to complete\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:16.633  waiting for load job to complete\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:17.724  Done with table bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081643503488292  2020-04-02 14:16:17.724  Done for data set tiny1\n",
            "D      LCF   1081643503488292  2020-04-02 14:16:17.726  Function execution took 18464 ms, finished with status: 'ok'\n",
            "D      LCF   1081657685723343  2020-04-02 14:22:53.337  Function execution started\n",
            "I      LCF   1081657685723343  2020-04-02 14:22:59.763  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1081657685723343  2020-04-02 14:22:59.763  Context: {event_id: 1081657685723343, timestamp: 2020-04-02T14:22:47.180Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1081657685723343  2020-04-02 14:22:59.763  Dataset: tiny1\n",
            "I      LCF   1081657685723343  2020-04-02 14:22:59.763  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_mc8o10_6/output.zip\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:00.520  Unzipping /tmp/LCF_mc8o10_6/output.zip\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:00.604  Unzipping done\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:00.604  Deleting previous BiqQuery dataset (if any)\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:01.202  Created BiqQuery dataset\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:01.202  Reading Parquet files from /tmp/LCF_mc8o10_6/movies_agg.parquet\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:01.357     movieId                        title  year  imdbId  numRatings  avgRating\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:01.357  0        1                    Toy Story  1995  114709         215   3.920930\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:01.357  1        2                      Jumanji  1995  113497         110   3.431818\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:01.357  2        3             Grumpier Old Men  1995  113228          52   3.259615\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:01.357  3        4            Waiting to Exhale  1995  114885           7   2.357143\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:01.357  4        5  Father of the Bride Part II  1995  113041          49   3.071429\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:01.357  Creating bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:01.602  Populating bigdata-269209.tiny1.movies_agg with 10 rows\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:03.153  waiting for load job to complete\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:04.270  waiting for load job to complete\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:05.342  waiting for load job to complete\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:06.465  waiting for load job to complete\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:07.565  waiting for load job to complete\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:08.654  Done with table bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:08.655  Reading Parquet files from /tmp/LCF_mc8o10_6/tfidf.parquet\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:09.302     movieId      word    tf_idf\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:09.302  0        3       ann  1.660964\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:09.302  1        1       tom  1.160964\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:09.302  2       10  scorupco  3.321928\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:09.302  3        1  children  0.868483\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:09.302  4        9    boothe  3.321928\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:09.303  Creating bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:09.483  Populating bigdata-269209.tiny1.tfidf with 142 rows\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:10.956  waiting for load job to complete\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:12.024  waiting for load job to complete\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:13.101  waiting for load job to complete\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:14.174  waiting for load job to complete\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:15.270  waiting for load job to complete\n",
            "D      LCF   1081666864171363  2020-04-02 14:23:15.767  Function execution started\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:16.363  waiting for load job to complete\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:17.470  Done with table bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081657685723343  2020-04-02 14:23:17.470  Done for data set tiny1\n",
            "D      LCF   1081657685723343  2020-04-02 14:23:17.477  Function execution took 24142 ms, finished with status: 'ok'\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:21.016  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:21.016  Context: {event_id: 1081666864171363, timestamp: 2020-04-02T14:23:11.558Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:21.016  Dataset: tiny1\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:21.016  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_fv6wrpwj/output.zip\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:21.295  Unzipping /tmp/LCF_fv6wrpwj/output.zip\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:21.329  Unzipping done\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:21.329  Deleting previous BiqQuery dataset (if any)\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:22.001  Created BiqQuery dataset\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:22.001  Reading Parquet files from /tmp/LCF_fv6wrpwj/movies_agg.parquet\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:22.120     movieId                        title  year  imdbId  numRatings  avgRating\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:22.120  0        1                    Toy Story  1995  114709         215   3.920930\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:22.120  1        2                      Jumanji  1995  113497         110   3.431818\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:22.120  2        3             Grumpier Old Men  1995  113228          52   3.259615\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:22.120  3        4            Waiting to Exhale  1995  114885           7   2.357143\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:22.120  4        5  Father of the Bride Part II  1995  113041          49   3.071429\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:22.120  Creating bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:22.446  Populating bigdata-269209.tiny1.movies_agg with 10 rows\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:25.271  waiting for load job to complete\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:26.364  waiting for load job to complete\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:27.452  waiting for load job to complete\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:28.526  waiting for load job to complete\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:29.614  waiting for load job to complete\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:30.689  Done with table bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:30.689\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:30.689  Reading Parquet files from /tmp/LCF_fv6wrpwj/tfidf.parquet\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:31.071     movieId      word    tf_idf\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:31.071  0        3       ann  1.660964\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:31.071  1        1       tom  1.160964\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:31.071  2       10  scorupco  3.321928\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:31.071  3        1  children  0.868483\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:31.071  4        9    boothe  3.321928\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:31.071  Creating bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:31.277  Populating bigdata-269209.tiny1.tfidf with 142 rows\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:32.383  waiting for load job to complete\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:33.518  waiting for load job to complete\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:34.587  waiting for load job to complete\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:35.708  waiting for load job to complete\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:36.798  waiting for load job to complete\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:37.912  waiting for load job to complete\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:38.992  waiting for load job to complete\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:40.088  Done with table bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081666864171363  2020-04-02 14:23:40.088  Done for data set tiny1\n",
            "D      LCF   1081666864171363  2020-04-02 14:23:40.092  Function execution took 24326 ms, finished with status: 'ok'\n",
            "D      LCF   1081676290237912  2020-04-02 14:25:33.216  Function execution started\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:33.224  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:33.224  Context: {event_id: 1081676290237912, timestamp: 2020-04-02T14:25:33.078Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:33.224  Dataset: tiny1\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:33.224  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_mc8o10_6/output.zip\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:33.904  Unzipping /tmp/LCF_mc8o10_6/output.zip\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:34.214  Unzipping done\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:34.214  Deleting previous BiqQuery dataset (if any)\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:34.892  Created BiqQuery dataset\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:34.892  Reading Parquet files from /tmp/LCF_mc8o10_6/movies_agg.parquet\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:35.108     movieId                        title  year  imdbId  numRatings  avgRating\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:35.108  0        1                    Toy Story  1995  114709         215   3.920930\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:35.108  1        2                      Jumanji  1995  113497         110   3.431818\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:35.108  2        3             Grumpier Old Men  1995  113228          52   3.259615\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:35.108  3        4            Waiting to Exhale  1995  114885           7   2.357143\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:35.108  4        5  Father of the Bride Part II  1995  113041          49   3.071429\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:35.108  Creating bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:35.384  Populating bigdata-269209.tiny1.movies_agg with 10 rows\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:37.302  waiting for load job to complete\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:38.466  waiting for load job to complete\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:39.569  waiting for load job to complete\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:40.642  waiting for load job to complete\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:41.701  waiting for load job to complete\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:42.773  Done with table bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:42.773  Reading Parquet files from /tmp/LCF_mc8o10_6/tfidf.parquet\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:44.120     movieId      word    tf_idf\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:44.120  0        3       ann  1.660964\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:44.120  1        1       tom  1.160964\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:44.120  2       10  scorupco  3.321928\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:44.120  3        1  children  0.868483\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:44.120  4        9    boothe  3.321928\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:44.121  Creating bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:44.376  Populating bigdata-269209.tiny1.tfidf with 142 rows\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:45.465  waiting for load job to complete\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:46.574  waiting for load job to complete\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:47.618  waiting for load job to complete\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:48.708  waiting for load job to complete\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:49.870  waiting for load job to complete\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:50.934  Done with table bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081676290237912  2020-04-02 14:25:50.934  Done for data set tiny1\n",
            "D      LCF   1081676290237912  2020-04-02 14:25:50.937  Function execution took 17722 ms, finished with status: 'ok'\n",
            "D      LCF   1081675273862862  2020-04-02 14:25:54.582  Function execution started\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:00.552  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:00.552  Context: {event_id: 1081675273862862, timestamp: 2020-04-02T14:25:50.163Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:00.552  Dataset: tiny1\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:00.552  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_ermxp9vv/output.zip\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:01.432  Unzipping /tmp/LCF_ermxp9vv/output.zip\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:01.479  Unzipping done\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:01.480  Deleting previous BiqQuery dataset (if any)\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:02.198  Created BiqQuery dataset\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:02.198  Reading Parquet files from /tmp/LCF_ermxp9vv/movies_agg.parquet\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:02.393     movieId                        title  year  imdbId  numRatings  avgRating\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:02.393  0        1                    Toy Story  1995  114709         215   3.920930\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:02.393  1        2                      Jumanji  1995  113497         110   3.431818\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:02.393  2        3             Grumpier Old Men  1995  113228          52   3.259615\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:02.393  3        4            Waiting to Exhale  1995  114885           7   2.357143\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:02.393  4        5  Father of the Bride Part II  1995  113041          49   3.071429\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:02.393  Creating bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:02.670  Populating bigdata-269209.tiny1.movies_agg with 10 rows\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:03.966  waiting for load job to complete\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:05.035  waiting for load job to complete\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:06.110  waiting for load job to complete\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:07.176  waiting for load job to complete\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:08.249  waiting for load job to complete\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:09.302  Done with table bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:09.302  Reading Parquet files from /tmp/LCF_ermxp9vv/tfidf.parquet\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:09.783     movieId      word    tf_idf\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:09.783  0        3       ann  1.660964\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:09.783  1        1       tom  1.160964\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:09.783  2       10  scorupco  3.321928\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:09.783  3        1  children  0.868483\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:09.783  4        9    boothe  3.321928\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:09.784  Creating bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:09.982  Populating bigdata-269209.tiny1.tfidf with 142 rows\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:11.496  waiting for load job to complete\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:12.581  waiting for load job to complete\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:13.657  waiting for load job to complete\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:14.724  waiting for load job to complete\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:15.798  waiting for load job to complete\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:16.856  Done with table bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081675273862862  2020-04-02 14:26:16.857  Done for data set tiny1\n",
            "D      LCF   1081675273862862  2020-04-02 14:26:16.862  Function execution took 22283 ms, finished with status: 'ok'\n",
            "D      LCF   1081709169342945  2020-04-02 14:43:45.353  Function execution started\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:52.543  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:52.543  Context: {event_id: 1081709169342945, timestamp: 2020-04-02T14:43:39.416Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:52.543  Dataset: tiny1\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:52.543  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_767apb66/output.zip\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:52.897  Unzipping /tmp/LCF_767apb66/output.zip\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:52.990  Unzipping done\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:52.990  Deleting previous BiqQuery dataset (if any)\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:53.798  Created BiqQuery dataset\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:53.798  Reading Parquet files from /tmp/LCF_767apb66/movies_agg.parquet\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:54.008     movieId                        title  year  imdbId  numRatings  avgRating\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:54.008  0        1                    Toy Story  1995  114709         215   3.920930\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:54.008  1        2                      Jumanji  1995  113497         110   3.431818\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:54.008  2        3             Grumpier Old Men  1995  113228          52   3.259615\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:54.008  3        4            Waiting to Exhale  1995  114885           7   2.357143\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:54.008  4        5  Father of the Bride Part II  1995  113041          49   3.071429\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:54.008  Creating bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:54.326  Populating bigdata-269209.tiny1.movies_agg with 10 rows\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:55.802  waiting for load job to complete\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:56.936  waiting for load job to complete\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:57.996  waiting for load job to complete\n",
            "I      LCF   1081709169342945  2020-04-02 14:43:59.065  waiting for load job to complete\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:00.128  waiting for load job to complete\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:01.214  Done with table bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:01.214  Reading Parquet files from /tmp/LCF_767apb66/tfidf.parquet\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:01.656     movieId      word    tf_idf\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:01.656  0        3       ann  1.660964\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:01.656  1        1       tom  1.160964\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:01.656  2       10  scorupco  3.321928\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:01.656  3        1  children  0.868483\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:01.656  4        9    boothe  3.321928\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:01.656  Creating bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:01.871  Populating bigdata-269209.tiny1.tfidf with 142 rows\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:03.302  waiting for load job to complete\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:04.367  waiting for load job to complete\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:05.445  waiting for load job to complete\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:06.541  waiting for load job to complete\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:07.622  waiting for load job to complete\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:08.696  Done with table bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081709169342945  2020-04-02 14:44:08.696  Done for data set tiny1\n",
            "D      LCF   1081709169342945  2020-04-02 14:44:08.699  Function execution took 23348 ms, finished with status: 'ok'\n",
            "D      LCF   1081701670924792  2020-04-02 14:44:15.227  Function execution started\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:15.248  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:15.248  Context: {event_id: 1081701670924792, timestamp: 2020-04-02T14:44:15.088Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:15.248  Dataset: tiny1\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:15.248  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_767apb66/output.zip\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:15.534  Unzipping /tmp/LCF_767apb66/output.zip\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:15.744  Unzipping done\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:15.745  Deleting previous BiqQuery dataset (if any)\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:16.384  Created BiqQuery dataset\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:16.384  Reading Parquet files from /tmp/LCF_767apb66/movies_agg.parquet\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:16.744     movieId                        title  year  imdbId  numRatings  avgRating\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:16.744  0        1                    Toy Story  1995  114709         215   3.920930\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:16.744  1        2                      Jumanji  1995  113497         110   3.431818\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:16.744  2        3             Grumpier Old Men  1995  113228          52   3.259615\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:16.744  3        4            Waiting to Exhale  1995  114885           7   2.357143\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:16.744  4        5  Father of the Bride Part II  1995  113041          49   3.071429\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:16.744  Creating bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:16.972  Populating bigdata-269209.tiny1.movies_agg with 10 rows\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:18.491  waiting for load job to complete\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:19.606  waiting for load job to complete\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:20.672  waiting for load job to complete\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:21.750  waiting for load job to complete\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:22.901  waiting for load job to complete\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:23.977  Done with table bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:23.977  Reading Parquet files from /tmp/LCF_767apb66/tfidf.parquet\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:25.241     movieId      word    tf_idf\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:25.241  0        3       ann  1.660964\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:25.241  1        1       tom  1.160964\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:25.241  2       10  scorupco  3.321928\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:25.241  3        1  children  0.868483\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:25.241  4        9    boothe  3.321928\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:25.242  Creating bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:25.528  Populating bigdata-269209.tiny1.tfidf with 142 rows\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:26.992  waiting for load job to complete\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:28.103  waiting for load job to complete\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:29.165  waiting for load job to complete\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:30.404  waiting for load job to complete\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:31.453  waiting for load job to complete\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:32.601  Done with table bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081701670924792  2020-04-02 14:44:32.601  Done for data set tiny1\n",
            "D      LCF   1081701670924792  2020-04-02 14:44:32.604  Function execution took 17379 ms, finished with status: 'ok'\n",
            "D      LCF   1081703221352838  2020-04-02 14:44:35.247  Function execution started\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:35.257  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:35.257  Context: {event_id: 1081703221352838, timestamp: 2020-04-02T14:44:35.118Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:35.257  Dataset: tiny1\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:35.257  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_mc8o10_6/output.zip\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:35.499  Unzipping /tmp/LCF_mc8o10_6/output.zip\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:35.813  Unzipping done\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:35.813  Deleting previous BiqQuery dataset (if any)\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:36.506  Created BiqQuery dataset\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:36.506  Reading Parquet files from /tmp/LCF_mc8o10_6/movies_agg.parquet\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:36.802     movieId                        title  year  imdbId  numRatings  avgRating\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:36.802  0        1                    Toy Story  1995  114709         215   3.920930\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:36.802  1        2                      Jumanji  1995  113497         110   3.431818\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:36.802  2        3             Grumpier Old Men  1995  113228          52   3.259615\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:36.802  3        4            Waiting to Exhale  1995  114885           7   2.357143\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:36.802  4        5  Father of the Bride Part II  1995  113041          49   3.071429\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:36.802  Creating bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:37.102  Populating bigdata-269209.tiny1.movies_agg with 10 rows\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:38.474  waiting for load job to complete\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:39.540  waiting for load job to complete\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:40.613  waiting for load job to complete\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:41.765  waiting for load job to complete\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:42.967  waiting for load job to complete\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:44.065  Done with table bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:44.065  Reading Parquet files from /tmp/LCF_mc8o10_6/tfidf.parquet\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:45.225     movieId      word    tf_idf\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:45.225  0        3       ann  1.660964\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:45.225  1        1       tom  1.160964\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:45.225  2       10  scorupco  3.321928\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:45.225  3        1  children  0.868483\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:45.225  4        9    boothe  3.321928\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:45.225  Creating bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:45.478  Populating bigdata-269209.tiny1.tfidf with 142 rows\n",
            "D      LCF   1081681021252893  2020-04-02 14:44:45.675  Function execution started\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:46.670  waiting for load job to complete\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:47.756  waiting for load job to complete\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:48.849  waiting for load job to complete\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:49.970  waiting for load job to complete\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:51.069  waiting for load job to complete\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:51.829  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:51.829  Context: {event_id: 1081681021252893, timestamp: 2020-04-02T14:44:40.402Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:51.829  Dataset: tiny1\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:51.829  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_9pbv1fho/output.zip\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:52.169  Done with table bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081703221352838  2020-04-02 14:44:52.169  Done for data set tiny1\n",
            "D      LCF   1081703221352838  2020-04-02 14:44:52.176  Function execution took 16929 ms, finished with status: 'ok'\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:52.296  Unzipping /tmp/LCF_9pbv1fho/output.zip\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:52.333  Unzipping done\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:52.333  Deleting previous BiqQuery dataset (if any)\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:53.027  Created BiqQuery dataset\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:53.027  Reading Parquet files from /tmp/LCF_9pbv1fho/movies_agg.parquet\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:53.188     movieId                        title  year  imdbId  numRatings  avgRating\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:53.188  0        1                    Toy Story  1995  114709         215   3.920930\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:53.188  1        2                      Jumanji  1995  113497         110   3.431818\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:53.188  2        3             Grumpier Old Men  1995  113228          52   3.259615\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:53.188  3        4            Waiting to Exhale  1995  114885           7   2.357143\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:53.188  4        5  Father of the Bride Part II  1995  113041          49   3.071429\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:53.188  Creating bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:53.386  Populating bigdata-269209.tiny1.movies_agg with 10 rows\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:54.852  waiting for load job to complete\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:55.927  waiting for load job to complete\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:57.091  waiting for load job to complete\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:58.191  waiting for load job to complete\n",
            "I      LCF   1081681021252893  2020-04-02 14:44:59.282  waiting for load job to complete\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:00.346  Done with table bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:00.346  Reading Parquet files from /tmp/LCF_9pbv1fho/tfidf.parquet\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:00.868     movieId      word    tf_idf\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:00.868  0        3       ann  1.660964\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:00.868  1        1       tom  1.160964\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:00.868  2       10  scorupco  3.321928\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:00.868  3        1  children  0.868483\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:00.868  4        9    boothe  3.321928\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:00.869  Creating bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:01.076  Populating bigdata-269209.tiny1.tfidf with 142 rows\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:02.600  waiting for load job to complete\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:03.677  waiting for load job to complete\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:04.783  waiting for load job to complete\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:05.879  waiting for load job to complete\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:06.939  waiting for load job to complete\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:08.018  Done with table bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081681021252893  2020-04-02 14:45:08.019  Done for data set tiny1\n",
            "D      LCF   1081681021252893  2020-04-02 14:45:08.021  Function execution took 22348 ms, finished with status: 'ok'\n",
            "D      LCF   1081718092621721  2020-04-02 14:46:18.704  Function execution started\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:18.713  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:18.713  Context: {event_id: 1081718092621721, timestamp: 2020-04-02T14:46:18.541Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:18.713  Dataset: tiny1\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:18.713  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_mc8o10_6/output.zip\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:18.904  Unzipping /tmp/LCF_mc8o10_6/output.zip\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:19.203  Unzipping done\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:19.204  Deleting previous BiqQuery dataset (if any)\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:19.804  Created BiqQuery dataset\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:19.804  Reading Parquet files from /tmp/LCF_mc8o10_6/movies_agg.parquet\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:20.009     movieId                        title  year  imdbId  numRatings  avgRating\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:20.009  0        1                    Toy Story  1995  114709         215   3.920930\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:20.009  1        2                      Jumanji  1995  113497         110   3.431818\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:20.009  2        3             Grumpier Old Men  1995  113228          52   3.259615\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:20.009  3        4            Waiting to Exhale  1995  114885           7   2.357143\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:20.009  4        5  Father of the Bride Part II  1995  113041          49   3.071429\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:20.010  Creating bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:20.284  Populating bigdata-269209.tiny1.movies_agg with 10 rows\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:21.777  waiting for load job to complete\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:22.969  waiting for load job to complete\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:24.057  waiting for load job to complete\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:25.153  waiting for load job to complete\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:26.375  waiting for load job to complete\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:27.448  Done with table bigdata-269209.tiny1.movies_agg\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:27.448  Reading Parquet files from /tmp/LCF_mc8o10_6/tfidf.parquet\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:28.707     movieId      word    tf_idf\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:28.707  0        3       ann  1.660964\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:28.707  1        1       tom  1.160964\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:28.707  2       10  scorupco  3.321928\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:28.707  3        1  children  0.868483\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:28.707  4        9    boothe  3.321928\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:28.708  Creating bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:28.872  Populating bigdata-269209.tiny1.tfidf with 142 rows\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:30.131  waiting for load job to complete\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:31.267  waiting for load job to complete\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:32.309  waiting for load job to complete\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:33.402  waiting for load job to complete\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:34.552  waiting for load job to complete\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:35.770  Done with table bigdata-269209.tiny1.tfidf\n",
            "I      LCF   1081718092621721  2020-04-02 14:46:35.770  Done for data set tiny1\n",
            "D      LCF   1081718092621721  2020-04-02 14:46:35.771  Function execution took 17069 ms, finished with status: 'ok'\n",
            "D      LCF   1113086551298433  2020-04-04 16:45:58.707  Function execution started\n",
            "I      LCF   1113086551298433  2020-04-04 16:46:05.033  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1113086551298433  2020-04-04 16:46:05.033  Context: {event_id: 1113086551298433, timestamp: 2020-04-04T16:45:51.175Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1113086551298433  2020-04-04 16:46:05.034  Dataset: tiny1\n",
            "I      LCF   1113086551298433  2020-04-04 16:46:05.034  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_qslbusom/output.zip\n",
            "I      LCF   1113086551298433  2020-04-04 16:46:05.799  Unzipping /tmp/LCF_qslbusom/output.zip\n",
            "I      LCF   1113086551298433  2020-04-04 16:46:05.843  Unzipping done\n",
            "I      LCF   1113086551298433  2020-04-04 16:46:05.843  Deleting previous BiqQuery dataset (if any)\n",
            "E      LCF   1113086551298433  2020-04-04 16:46:06.029  Traceback (most recent call last):\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 383, in run_background_function\n",
            "                                                            _function_handler.invoke_user_function(event_object)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 217, in invoke_user_function\n",
            "                                                            return call_user_function(request_or_event)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 214, in call_user_function\n",
            "                                                            event_context.Context(**request_or_event.context))\n",
            "                                                          File \"/user_code/main.py\", line 135, in handle_pubsub_message\n",
            "                                                            BQ_CLIENT.delete_dataset(dataset_id, delete_contents = True, not_found_ok = True)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 1119, in delete_dataset\n",
            "                                                            timeout=timeout,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 556, in _call_api\n",
            "                                                            return call()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 286, in retry_wrapped_func\n",
            "                                                            on_error=on_error,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 184, in retry_target\n",
            "                                                            return target()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/_http.py\", line 423, in api_request\n",
            "                                                            raise exceptions.from_http_response(response)\n",
            "                                                        google.api_core.exceptions.Forbidden: 403 DELETE https://bigquery.googleapis.com/bigquery/v2/projects/bigdata-269209/datasets/tiny1?deleteContents=true: Access Denied: Dataset bigdata-269209:tiny1: User does not have bigquery.datasets.delete permission for dataset bigdata-269209:tiny1.\n",
            "D      LCF   1113086551298433  2020-04-04 16:46:06.032  Function execution took 7327 ms, finished with status: 'crash'\n",
            "D      LCF   1096062940330139  2020-04-07 14:05:27.891  Function execution started\n",
            "I      LCF   1096062940330139  2020-04-07 14:05:33.385  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1096062940330139  2020-04-07 14:05:33.385  Context: {event_id: 1096062940330139, timestamp: 2020-04-07T14:05:21.600Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1096062940330139  2020-04-07 14:05:33.385  Dataset: tiny1\n",
            "I      LCF   1096062940330139  2020-04-07 14:05:33.386  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_o7avzgp1/output.zip\n",
            "I      LCF   1096062940330139  2020-04-07 14:05:33.985  Unzipping /tmp/LCF_o7avzgp1/output.zip\n",
            "I      LCF   1096062940330139  2020-04-07 14:05:34.036  Unzipping done\n",
            "I      LCF   1096062940330139  2020-04-07 14:05:34.037  Deleting previous BiqQuery dataset (if any)\n",
            "E      LCF   1096062940330139  2020-04-07 14:05:34.239  Traceback (most recent call last):\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 383, in run_background_function\n",
            "                                                            _function_handler.invoke_user_function(event_object)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 217, in invoke_user_function\n",
            "                                                            return call_user_function(request_or_event)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 214, in call_user_function\n",
            "                                                            event_context.Context(**request_or_event.context))\n",
            "                                                          File \"/user_code/main.py\", line 135, in handle_pubsub_message\n",
            "                                                            BQ_CLIENT.delete_dataset(dataset_id, delete_contents = True, not_found_ok = True)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 1119, in delete_dataset\n",
            "                                                            timeout=timeout,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 556, in _call_api\n",
            "                                                            return call()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 286, in retry_wrapped_func\n",
            "                                                            on_error=on_error,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 184, in retry_target\n",
            "                                                            return target()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/_http.py\", line 423, in api_request\n",
            "                                                            raise exceptions.from_http_response(response)\n",
            "                                                        google.api_core.exceptions.Forbidden: 403 DELETE https://bigquery.googleapis.com/bigquery/v2/projects/bigdata-269209/datasets/tiny1?deleteContents=true: Access Denied: Dataset bigdata-269209:tiny1: User does not have bigquery.datasets.delete permission for dataset bigdata-269209:tiny1.\n",
            "D      LCF   1096062940330139  2020-04-07 14:05:34.242  Function execution took 6353 ms, finished with status: 'crash'\n",
            "D      LCF   1096296287025014  2020-04-07 16:36:17.101  Function execution started\n",
            "I      LCF   1096296287025014  2020-04-07 16:36:22.149  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1096296287025014  2020-04-07 16:36:22.149  Context: {event_id: 1096296287025014, timestamp: 2020-04-07T16:36:12.967Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1096296287025014  2020-04-07 16:36:22.150  Dataset: tiny1\n",
            "I      LCF   1096296287025014  2020-04-07 16:36:22.150  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_wkablu74/output.zip\n",
            "I      LCF   1096296287025014  2020-04-07 16:36:23.187  Unzipping /tmp/LCF_wkablu74/output.zip\n",
            "I      LCF   1096296287025014  2020-04-07 16:36:23.391  Unzipping done\n",
            "I      LCF   1096296287025014  2020-04-07 16:36:23.392  Deleting previous BiqQuery dataset (if any)\n",
            "E      LCF   1096296287025014  2020-04-07 16:36:23.635  Traceback (most recent call last):\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 383, in run_background_function\n",
            "                                                            _function_handler.invoke_user_function(event_object)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 217, in invoke_user_function\n",
            "                                                            return call_user_function(request_or_event)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 214, in call_user_function\n",
            "                                                            event_context.Context(**request_or_event.context))\n",
            "                                                          File \"/user_code/main.py\", line 135, in handle_pubsub_message\n",
            "                                                            BQ_CLIENT.delete_dataset(dataset_id, delete_contents = True, not_found_ok = True)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 1119, in delete_dataset\n",
            "                                                            timeout=timeout,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 556, in _call_api\n",
            "                                                            return call()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 286, in retry_wrapped_func\n",
            "                                                            on_error=on_error,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 184, in retry_target\n",
            "                                                            return target()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/_http.py\", line 423, in api_request\n",
            "                                                            raise exceptions.from_http_response(response)\n",
            "                                                        google.api_core.exceptions.Forbidden: 403 DELETE https://bigquery.googleapis.com/bigquery/v2/projects/bigdata-269209/datasets/tiny1?deleteContents=true: Access Denied: Dataset bigdata-269209:tiny1: User does not have bigquery.datasets.delete permission for dataset bigdata-269209:tiny1.\n",
            "D      LCF   1096296287025014  2020-04-07 16:36:23.639  Function execution took 6540 ms, finished with status: 'crash'\n",
            "D      LCF   1114729417605719  2020-04-07 17:25:21.808  Function execution started\n",
            "I      LCF   1114729417605719  2020-04-07 17:25:27.624  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1114729417605719  2020-04-07 17:25:27.624  Context: {event_id: 1114729417605719, timestamp: 2020-04-07T17:25:15.644Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1114729417605719  2020-04-07 17:25:27.624  Dataset: tiny1\n",
            "I      LCF   1114729417605719  2020-04-07 17:25:27.624  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF__gn54qc5/output.zip\n",
            "I      LCF   1114729417605719  2020-04-07 17:25:28.521  Unzipping /tmp/LCF__gn54qc5/output.zip\n",
            "I      LCF   1114729417605719  2020-04-07 17:25:28.767  Unzipping done\n",
            "I      LCF   1114729417605719  2020-04-07 17:25:28.767  Deleting previous BiqQuery dataset (if any)\n",
            "E      LCF   1114729417605719  2020-04-07 17:25:28.935  Traceback (most recent call last):\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 383, in run_background_function\n",
            "                                                            _function_handler.invoke_user_function(event_object)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 217, in invoke_user_function\n",
            "                                                            return call_user_function(request_or_event)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 214, in call_user_function\n",
            "                                                            event_context.Context(**request_or_event.context))\n",
            "                                                          File \"/user_code/main.py\", line 135, in handle_pubsub_message\n",
            "                                                            BQ_CLIENT.delete_dataset(dataset_id, delete_contents = True, not_found_ok = True)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 1119, in delete_dataset\n",
            "                                                            timeout=timeout,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 556, in _call_api\n",
            "                                                            return call()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 286, in retry_wrapped_func\n",
            "                                                            on_error=on_error,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 184, in retry_target\n",
            "                                                            return target()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/_http.py\", line 423, in api_request\n",
            "                                                            raise exceptions.from_http_response(response)\n",
            "                                                        google.api_core.exceptions.Forbidden: 403 DELETE https://bigquery.googleapis.com/bigquery/v2/projects/bigdata-269209/datasets/tiny1?deleteContents=true: Access Denied: Dataset bigdata-269209:tiny1: User does not have bigquery.datasets.delete permission for dataset bigdata-269209:tiny1.\n",
            "D      LCF   1114729417605719  2020-04-07 17:25:28.938  Function execution took 7132 ms, finished with status: 'crash'\n",
            "D      LCF   1114728076414702  2020-04-07 17:27:12.808  Function execution started\n",
            "I      LCF   1114728076414702  2020-04-07 17:27:17.999  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1114728076414702  2020-04-07 17:27:17.999  Context: {event_id: 1114728076414702, timestamp: 2020-04-07T17:27:08.709Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1114728076414702  2020-04-07 17:27:17.999  Dataset: tiny1\n",
            "I      LCF   1114728076414702  2020-04-07 17:27:17.999  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_67nqfob2/output.zip\n",
            "I      LCF   1114728076414702  2020-04-07 17:27:18.765  Unzipping /tmp/LCF_67nqfob2/output.zip\n",
            "I      LCF   1114728076414702  2020-04-07 17:27:18.982  Unzipping done\n",
            "I      LCF   1114728076414702  2020-04-07 17:27:18.982  Deleting previous BiqQuery dataset (if any)\n",
            "E      LCF   1114728076414702  2020-04-07 17:27:19.138  Traceback (most recent call last):\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 383, in run_background_function\n",
            "                                                            _function_handler.invoke_user_function(event_object)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 217, in invoke_user_function\n",
            "                                                            return call_user_function(request_or_event)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 214, in call_user_function\n",
            "                                                            event_context.Context(**request_or_event.context))\n",
            "                                                          File \"/user_code/main.py\", line 135, in handle_pubsub_message\n",
            "                                                            BQ_CLIENT.delete_dataset(dataset_id, delete_contents = True, not_found_ok = True)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 1119, in delete_dataset\n",
            "                                                            timeout=timeout,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 556, in _call_api\n",
            "                                                            return call()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 286, in retry_wrapped_func\n",
            "                                                            on_error=on_error,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 184, in retry_target\n",
            "                                                            return target()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/_http.py\", line 423, in api_request\n",
            "                                                            raise exceptions.from_http_response(response)\n",
            "                                                        google.api_core.exceptions.Forbidden: 403 DELETE https://bigquery.googleapis.com/bigquery/v2/projects/bigdata-269209/datasets/tiny1?deleteContents=true: Access Denied: Dataset bigdata-269209:tiny1: User does not have bigquery.datasets.delete permission for dataset bigdata-269209:tiny1.\n",
            "D      LCF   1114728076414702  2020-04-07 17:27:19.139  Function execution took 6332 ms, finished with status: 'crash'\n",
            "D      LCF   1114734844138548  2020-04-07 17:39:30.684  Function execution started\n",
            "I      LCF   1114734844138548  2020-04-07 17:39:36.118  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1114734844138548  2020-04-07 17:39:36.118  Context: {event_id: 1114734844138548, timestamp: 2020-04-07T17:39:26.570Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1114734844138548  2020-04-07 17:39:36.118  Dataset: tiny1\n",
            "I      LCF   1114734844138548  2020-04-07 17:39:36.118  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_iboth2mw/output.zip\n",
            "I      LCF   1114734844138548  2020-04-07 17:39:36.982  Unzipping /tmp/LCF_iboth2mw/output.zip\n",
            "I      LCF   1114734844138548  2020-04-07 17:39:37.252  Unzipping done\n",
            "I      LCF   1114734844138548  2020-04-07 17:39:37.253  Deleting previous BiqQuery dataset (if any)\n",
            "E      LCF   1114734844138548  2020-04-07 17:39:37.438  Traceback (most recent call last):\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 383, in run_background_function\n",
            "                                                            _function_handler.invoke_user_function(event_object)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 217, in invoke_user_function\n",
            "                                                            return call_user_function(request_or_event)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 214, in call_user_function\n",
            "                                                            event_context.Context(**request_or_event.context))\n",
            "                                                          File \"/user_code/main.py\", line 135, in handle_pubsub_message\n",
            "                                                            BQ_CLIENT.delete_dataset(dataset_id, delete_contents = True, not_found_ok = True)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 1119, in delete_dataset\n",
            "                                                            timeout=timeout,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 556, in _call_api\n",
            "                                                            return call()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 286, in retry_wrapped_func\n",
            "                                                            on_error=on_error,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 184, in retry_target\n",
            "                                                            return target()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/_http.py\", line 423, in api_request\n",
            "                                                            raise exceptions.from_http_response(response)\n",
            "                                                        google.api_core.exceptions.Forbidden: 403 DELETE https://bigquery.googleapis.com/bigquery/v2/projects/bigdata-269209/datasets/tiny1?deleteContents=true: Access Denied: Dataset bigdata-269209:tiny1: User does not have bigquery.datasets.delete permission for dataset bigdata-269209:tiny1.\n",
            "D      LCF   1114734844138548  2020-04-07 17:39:37.444  Function execution took 6762 ms, finished with status: 'crash'\n",
            "D      LCF   1115800287428475  2020-04-09 15:33:37.283  Function execution started\n",
            "I      LCF   1115800287428475  2020-04-09 15:33:43.312  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1115800287428475  2020-04-09 15:33:43.312  Context: {event_id: 1115800287428475, timestamp: 2020-04-09T15:33:31.971Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1115800287428475  2020-04-09 15:33:43.312  Dataset: tiny1\n",
            "I      LCF   1115800287428475  2020-04-09 15:33:43.312  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_klmt2lbj/output.zip\n",
            "I      LCF   1115800287428475  2020-04-09 15:33:44.210  Unzipping /tmp/LCF_klmt2lbj/output.zip\n",
            "I      LCF   1115800287428475  2020-04-09 15:33:44.451  Unzipping done\n",
            "I      LCF   1115800287428475  2020-04-09 15:33:44.451  Deleting previous BiqQuery dataset (if any)\n",
            "E      LCF   1115800287428475  2020-04-09 15:33:44.731  Traceback (most recent call last):\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 383, in run_background_function\n",
            "                                                            _function_handler.invoke_user_function(event_object)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 217, in invoke_user_function\n",
            "                                                            return call_user_function(request_or_event)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 214, in call_user_function\n",
            "                                                            event_context.Context(**request_or_event.context))\n",
            "                                                          File \"/user_code/main.py\", line 166, in handle_pubsub_message\n",
            "                                                            BQ_CLIENT.delete_dataset(dataset_id, delete_contents = True, not_found_ok = True)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 1119, in delete_dataset\n",
            "                                                            timeout=timeout,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 556, in _call_api\n",
            "                                                            return call()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 286, in retry_wrapped_func\n",
            "                                                            on_error=on_error,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 184, in retry_target\n",
            "                                                            return target()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/_http.py\", line 423, in api_request\n",
            "                                                            raise exceptions.from_http_response(response)\n",
            "                                                        google.api_core.exceptions.Forbidden: 403 DELETE https://bigquery.googleapis.com/bigquery/v2/projects/bigdata-269209/datasets/tiny1?deleteContents=true: Access Denied: Dataset bigdata-269209:tiny1: User does not have bigquery.datasets.delete permission for dataset bigdata-269209:tiny1.\n",
            "D      LCF   1115800287428475  2020-04-09 15:33:44.733  Function execution took 7452 ms, finished with status: 'crash'\n",
            "D      LCF   1100106615149321  2020-04-09 15:47:00.046  Function execution started\n",
            "I      LCF   1100106615149321  2020-04-09 15:47:06.144  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'dGlueTE='}\n",
            "I      LCF   1100106615149321  2020-04-09 15:47:06.144  Context: {event_id: 1100106615149321, timestamp: 2020-04-09T15:46:53.309Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1100106615149321  2020-04-09 15:47:06.144  Dataset: tiny1\n",
            "I      LCF   1100106615149321  2020-04-09 15:47:06.144  Downloading gs://zaoutputbucket/tiny1/output.zip to /tmp/LCF_vcmflprg/output.zip\n",
            "I      LCF   1100106615149321  2020-04-09 15:47:06.737  Unzipping /tmp/LCF_vcmflprg/output.zip\n",
            "I      LCF   1100106615149321  2020-04-09 15:47:07.044  Unzipping done\n",
            "I      LCF   1100106615149321  2020-04-09 15:47:07.045  Deleting previous BiqQuery dataset (if any)\n",
            "E      LCF   1100106615149321  2020-04-09 15:47:07.235  Traceback (most recent call last):\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 383, in run_background_function\n",
            "                                                            _function_handler.invoke_user_function(event_object)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 217, in invoke_user_function\n",
            "                                                            return call_user_function(request_or_event)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/functions/worker.py\", line 214, in call_user_function\n",
            "                                                            event_context.Context(**request_or_event.context))\n",
            "                                                          File \"/user_code/main.py\", line 166, in handle_pubsub_message\n",
            "                                                            BQ_CLIENT.delete_dataset(dataset_id, delete_contents = True, not_found_ok = True)\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 1119, in delete_dataset\n",
            "                                                            timeout=timeout,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/bigquery/client.py\", line 556, in _call_api\n",
            "                                                            return call()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 286, in retry_wrapped_func\n",
            "                                                            on_error=on_error,\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/api_core/retry.py\", line 184, in retry_target\n",
            "                                                            return target()\n",
            "                                                          File \"/env/local/lib/python3.7/site-packages/google/cloud/_http.py\", line 423, in api_request\n",
            "                                                            raise exceptions.from_http_response(response)\n",
            "                                                        google.api_core.exceptions.Forbidden: 403 DELETE https://bigquery.googleapis.com/bigquery/v2/projects/bigdata-269209/datasets/tiny1?deleteContents=true: Access Denied: Dataset bigdata-269209:tiny1: User does not have bigquery.datasets.delete permission for dataset bigdata-269209:tiny1.\n",
            "D      LCF   1100106615149321  2020-04-09 15:47:07.237  Function execution took 7192 ms, finished with status: 'crash'\n",
            "D      LCF   1100195585315863  2020-04-09 16:44:09.556  Function execution started\n",
            "I      LCF   1100195585315863  2020-04-09 16:44:15.923  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'bGFyZ2U1'}\n",
            "I      LCF   1100195585315863  2020-04-09 16:44:15.923  Context: {event_id: 1100195585315863, timestamp: 2020-04-09T16:44:03.637Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1100195585315863  2020-04-09 16:44:15.923  Dataset: large5\n",
            "I      LCF   1100195585315863  2020-04-09 16:44:15.923  Downloading gs://zaoutputbucket/large5/output.zip to /tmp/LCF_xzbjqs07/output.zip\n",
            "I      LCF   1100195585315863  2020-04-09 16:44:23.334  Unzipping /tmp/LCF_xzbjqs07/output.zip\n",
            "E      LCF   1100195585315863  2020-04-09 16:44:26.240  Error: memory limit exceeded. Function invocation was interrupted.\n",
            "D      LCF   1115837816550275  2020-04-09 16:52:49.761  Function execution started\n",
            "I      LCF   1115837816550275  2020-04-09 16:52:56.214  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'bGFyZ2U1'}\n",
            "I      LCF   1115837816550275  2020-04-09 16:52:56.214  Context: {event_id: 1115837816550275, timestamp: 2020-04-09T16:52:44.315Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1115837816550275  2020-04-09 16:52:56.214  Dataset: large5\n",
            "I      LCF   1115837816550275  2020-04-09 16:52:56.214  Downloading gs://zaoutputbucket/large5/output.zip to /tmp/LCF_gnc1mb4z/output.zip\n",
            "I      LCF   1115837816550275  2020-04-09 16:53:03.969  Unzipping /tmp/LCF_gnc1mb4z/output.zip\n",
            "E      LCF   1115837816550275  2020-04-09 16:53:06.936  Error: memory limit exceeded. Function invocation was interrupted.\n",
            "D      LCF   1100286638920641  2020-04-09 17:48:33.871  Function execution started\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:38.123  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'bGFyZ2U1'}\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:38.124  Context: {event_id: 1100286638920641, timestamp: 2020-04-09T17:48:30.389Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:38.124  Dataset: large5\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:38.124  Downloading gs://zaoutputbucket/large5/output.zip to /tmp/LCF_951ij6zx/output.zip\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:40.447  Unzipping /tmp/LCF_951ij6zx/output.zip\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:41.896  Unzipping done\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:41.897  Deleting previous BiqQuery dataset (if any)\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:42.429  Created BiqQuery dataset\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:42.429  Reading Parquet files from /tmp/LCF_951ij6zx/movies_agg.parquet\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:43.286     movieId                        title    year  imdbId  numRatings  avgRating\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:43.286  0        1                    Toy Story  1995.0  114709       57309   3.893708\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:43.286  1        2                      Jumanji  1995.0  113497       24228   3.251527\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:43.286  2        3             Grumpier Old Men  1995.0  113228       11804   3.142028\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:43.286  3        4            Waiting to Exhale  1995.0  114885        2523   2.853547\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:43.286  4        5  Father of the Bride Part II  1995.0  113041       11714   3.058434\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:43.286  Creating bigdata-269209.large5.movies_agg\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:43.506  Populating bigdata-269209.large5.movies_agg with 62345 rows\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:45.586  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:46.672  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:47.748  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:48.846  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:49.949  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:51.029  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:52.114  Done with table bigdata-269209.large5.movies_agg\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:52.116  Reading Parquet files from /tmp/LCF_951ij6zx/tfidf.parquet\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:53.702     movieId word    tf_idf\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:53.702  0    26413   07  2.476856\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:53.702  1    26560   07  1.415346\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:53.702  2     4856   07  0.762109\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:53.702  3    73587   07  2.476856\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:53.702  4    50742   07  1.651237\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:53.702  Creating bigdata-269209.large5.tfidf\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:53.993  Populating bigdata-269209.large5.tfidf with 1708627 rows\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:56.788  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:57.865  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:48:58.934  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:00.006  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:01.124  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:02.212  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:03.320  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:04.412  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:05.486  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:06.572  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:07.688  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:08.731  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:09.866  waiting for load job to complete\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:11.111  Done with table bigdata-269209.large5.tfidf\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:11.133  Reading Parquet files from /tmp/LCF_951ij6zx/ratings_tags.parquet\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:15.867     movieId      title  userId\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:15.867  0        1  Toy Story       2\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:15.867  1        1  Toy Story       3\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:15.867  2        1  Toy Story       4\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:15.867  3        1  Toy Story       5\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:15.867  4        1  Toy Story       8\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:15.867  Creating bigdata-269209.large5.ratings_tags\n",
            "I      LCF   1100286638920641  2020-04-09 17:49:16.358  Populating bigdata-269209.large5.ratings_tags with 25078468 rows\n",
            "D      LCF   1100286638920641  2020-04-09 17:49:33.882  Function execution took 60012 ms, finished with status: 'timeout'\n",
            "D      LCF   1100546807555506  2020-04-09 20:23:09.043  Function execution started\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:13.820  Event: {'@type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage', 'attributes': None, 'data': 'bGFyZ2U1'}\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:13.821  Context: {event_id: 1100546807555506, timestamp: 2020-04-09T20:23:05.715Z, event_type: google.pubsub.topic.publish, resource: {'service': 'pubsub.googleapis.com', 'name': 'projects/bigdata-269209/topics/new_output', 'type': 'type.googleapis.com/google.pubsub.v1.PubsubMessage'}}\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:13.821  Dataset: large5\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:13.821  Downloading gs://zaoutputbucket/large5/output.zip to /tmp/LCF_x30qhwee/output.zip\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:18.542  Unzipping /tmp/LCF_x30qhwee/output.zip\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:20.416  Unzipping done\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:20.417  Deleting previous BiqQuery dataset (if any)\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:21.112  Created BiqQuery dataset\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:21.113  Reading Parquet files from /tmp/LCF_x30qhwee/movies_agg.parquet\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:21.843     movieId                        title    year  imdbId  numRatings  avgRating\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:21.843  0        1                    Toy Story  1995.0  114709       57309   3.893708\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:21.843  1        2                      Jumanji  1995.0  113497       24228   3.251527\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:21.843  2        3             Grumpier Old Men  1995.0  113228       11804   3.142028\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:21.843  3        4            Waiting to Exhale  1995.0  114885        2523   2.853547\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:21.843  4        5  Father of the Bride Part II  1995.0  113041       11714   3.058434\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:21.844  Creating bigdata-269209.large5.movies_agg\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:22.093  Populating bigdata-269209.large5.movies_agg with 62345 rows\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:24.870  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:25.970  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:27.098  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:28.171  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:29.296  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:30.373  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:31.456  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:32.530  Done with table bigdata-269209.large5.movies_agg\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:32.532  Reading Parquet files from /tmp/LCF_x30qhwee/tfidf.parquet\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:34.191     movieId word    tf_idf\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:34.191  0    26413   07  2.476856\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:34.191  1    26560   07  1.415346\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:34.191  2     4856   07  0.762109\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:34.191  3    73587   07  2.476856\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:34.191  4    50742   07  1.651237\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:34.191  Creating bigdata-269209.large5.tfidf\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:34.523  Populating bigdata-269209.large5.tfidf with 1708627 rows\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:37.178  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:38.264  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:39.430  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:40.517  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:41.621  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:42.716  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:43.800  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:44.888  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:45.965  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:47.033  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:48.119  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:49.205  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:50.316  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:51.393  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:52.465  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:53.539  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:54.616  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:55.701  waiting for load job to complete\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:56.822  Done with table bigdata-269209.large5.tfidf\n",
            "I      LCF   1100546807555506  2020-04-09 20:23:56.922  Reading Parquet files from /tmp/LCF_x30qhwee/ratings_tags.parquet\n",
            "I      LCF   1100546807555506  2020-04-09 20:24:00.626     movieId      title  userId\n",
            "I      LCF   1100546807555506  2020-04-09 20:24:00.626  0        1  Toy Story       2\n",
            "I      LCF   1100546807555506  2020-04-09 20:24:00.626  1        1  Toy Story       3\n",
            "I      LCF   1100546807555506  2020-04-09 20:24:00.626  2        1  Toy Story       4\n",
            "I      LCF   1100546807555506  2020-04-09 20:24:00.626  3        1  Toy Story       5\n",
            "I      LCF   1100546807555506  2020-04-09 20:24:00.626  4        1  Toy Story       8\n",
            "I      LCF   1100546807555506  2020-04-09 20:24:00.627  Creating bigdata-269209.large5.ratings_tags\n",
            "I      LCF   1100546807555506  2020-04-09 20:24:00.904  Populating bigdata-269209.large5.ratings_tags with 25078468 rows\n",
            "D      LCF   1100546807555506  2020-04-09 20:24:09.054  Function execution took 60013 ms, finished with status: 'timeout'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}